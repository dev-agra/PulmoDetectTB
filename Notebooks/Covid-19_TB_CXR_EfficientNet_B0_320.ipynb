{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 40178,
     "status": "ok",
     "timestamp": 1588213047201,
     "user": {
      "displayName": "DUONG TUAN LINH",
      "photoUrl": "",
      "userId": "10844282398210252241"
     },
     "user_tz": -420
    },
    "id": "rPwL9bdoBNzQ",
    "outputId": "553f83f0-cbf1-48d5-a184-4f4c8ff055ac"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import PIL\n",
    "import sys\n",
    "import json\n",
    "import time\n",
    "import timm\n",
    "import math\n",
    "import copy\n",
    "import torch\n",
    "import pickle\n",
    "import logging\n",
    "import fnmatch\n",
    "import argparse\n",
    "import itertools\n",
    "import torchvision\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import albumentations\n",
    "import torch.nn as nn\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "from copy import deepcopy\n",
    "import scikitplot as skplt\n",
    "from sklearn import metrics\n",
    "import torch.optim as optim\n",
    "from datetime import datetime\n",
    "from timm.data.loader import *\n",
    "from torchvision import models\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as data\n",
    "from cutmix.cutmix import CutMix\n",
    "from torch.autograd import Variable\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "from torch.optim import lr_scheduler\n",
    "#from pytorch_metric_learning import loss\n",
    "import torch.utils.model_zoo as model_zoo\n",
    "from timm.models.layers.activations import *\n",
    "from timm.utils import accuracy, AverageMeter\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "from cutmix.utils import CutMixCrossEntropyLoss\n",
    "from collections import OrderedDict, defaultdict\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from warmup_scheduler import GradualWarmupScheduler\n",
    "from torchvision import transforms, models, datasets\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from randaugment import RandAugment, ImageNetPolicy, Cutout\n",
    "from timm.loss import LabelSmoothingCrossEntropy, SoftTargetCrossEntropy\n",
    "from sklearn.metrics import classification_report, confusion_matrix,accuracy_score, roc_curve, auc, roc_auc_score\n",
    "#from timm.data import Dataset, DatasetTar, RealLabelsImagenet, create_loader, Mixup, FastCollateMixup, AugMixDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.backends.cudnn.benchmark = True\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 179460,
     "status": "ok",
     "timestamp": 1588213186502,
     "user": {
      "displayName": "DUONG TUAN LINH",
      "photoUrl": "",
      "userId": "10844282398210252241"
     },
     "user_tz": -420
    },
    "id": "yyGpxuktB96O",
    "outputId": "584ea32f-dbe1-4465-8e60-e0f4e5c96a6f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['COVID-19', 'NORMAL', 'NOT NORMAL & NO LUNG OPACITY', 'PNEUMONIA', 'TB']\n",
      "{'train': 24722, 'val': 3236, 'test': 3238}\n",
      "cuda:0\n",
      "{0: 'COVID-19', 1: 'NORMAL', 2: 'NOT NORMAL & NO LUNG OPACITY', 3: 'PNEUMONIA', 4: 'TB'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 3, 240, 240])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#data_dir = '/home/linh/Downloads/TB/'\n",
    "#data_dir = '/home/linh/Downloads/Covid-19/CXR_20201006/data_20201006/'\n",
    "data_dir = '/home/linh/Downloads/TB_COVID-19/data'\n",
    "\n",
    "device = torch.device(\"cuda:0\")\n",
    "batch_size = 64\n",
    "# batch_size (48 or 50 for EfficientNet-B0, img_size=320, cuda=0 or cuda=1) \n",
    "# batch_size (66 or 68 for EfficientNet-B1, img_size=240, cuda=0 or cuda=1)\n",
    "num_epochs = 450\n",
    "lr = 0.01\n",
    "beta = 1\n",
    "step_size = 100\n",
    "img_size = 240 #320 #240\n",
    "test_size = int((256 / 224) * img_size)\n",
    "mean = [0.485, 0.456, 0.406] \n",
    "std = [0.229, 0.224, 0.225]\n",
    "num_workers = 4\n",
    "# Define your transforms for the training and testing sets\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomRotation(30),\n",
    "        transforms.RandomResizedCrop(img_size),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ColorJitter(0.3, 0.3, 0.3),\n",
    "        RandAugment(),\n",
    "        ImageNetPolicy(),\n",
    "        Cutout(size=16),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean, std),\n",
    "        transforms.RandomErasing()\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize(test_size),\n",
    "        transforms.CenterCrop(img_size),\n",
    "        transforms.ColorJitter(0.5, 0.5, 0.5),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean, std)\n",
    "    ]),\n",
    "    'test': transforms.Compose([\n",
    "        transforms.Resize(test_size),\n",
    "        transforms.CenterCrop(img_size),\n",
    "        transforms.ColorJitter(0.5, 0.5, 0.5),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean, std)\n",
    "    ])\n",
    "}\n",
    "\n",
    "# Load the datasets with ImageFolder\n",
    "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x), data_transforms[x]) for x in ['train', 'val', 'test']}\n",
    "class_names = image_datasets['train'].classes\n",
    "num_classes = len(class_names)\n",
    "data_loader = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=batch_size,\n",
    "                                             shuffle=True, num_workers=num_workers, pin_memory = True)\n",
    "              for x in ['train', 'val', 'test']}\n",
    "\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val', 'test']}\n",
    "\n",
    "print(class_names)\n",
    "print(dataset_sizes)\n",
    "print(device)\n",
    "\n",
    "### we get the class_to_index in the data_Set but what we really need is the cat_to_names  so we will create\n",
    "_ = image_datasets['val'].class_to_idx\n",
    "cat_to_name = {_[i]: i for i in list(_.keys())}\n",
    "print(cat_to_name)\n",
    "    \n",
    "# Run this to test the data loader\n",
    "images, labels = next(iter(data_loader['val']))\n",
    "images.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.suam(axis=1)[:, np.newaxis]\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    \n",
    "def plot_roc_curve(fpr, tpr):\n",
    "    plt.plot(fpr, tpr, color='darkorange',\n",
    "         lw=2, label='ROC curve (area = %0.4f)' % roc_auc)\n",
    "    plt.plot([0, 1], [0, 1], color='darkblue', linestyle='--')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "    plt.legend(loc=\"lower right\")  \n",
    "    plt.show()\n",
    "    \n",
    "def plt_roc(test_y, probas_y, plot_micro=False, plot_macro=False):\n",
    "    assert isinstance(test_y, list) and isinstance(probas_y, list), 'the type of input must be list'\n",
    "    \n",
    "    skplt.metrics.plot_roc(test_y, probas_y, plot_micro=plot_micro,plot_macro=plot_macro, figsize=(10, 8))\n",
    "    #plt.savefig(add_prefix(args.prefix, 'roc_auc_curve.png'))\n",
    "    plt.show()\n",
    "    #plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 603
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 226470,
     "status": "ok",
     "timestamp": 1588213233519,
     "user": {
      "displayName": "DUONG TUAN LINH",
      "photoUrl": "",
      "userId": "10844282398210252241"
     },
     "user_tz": -420
    },
    "id": "N350JAHpu8c3",
    "outputId": "96a2d095-f78f-4ca5-eb0c-c5390e367831"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"def showimage(data_loader, number_images, cat_to_name):\\n    dataiter = iter(data_loader)\\n    images, labels = dataiter.next()\\n    images = images.numpy() # convert images to numpy for display\\n    # plot the images in the batch, along with the corresponding labels\\n    fig = plt.figure(figsize=(number_images, 4))\\n    for idx in np.arange(number_images):\\n        ax = fig.add_subplot(4, number_images/2, idx+1, xticks=[], yticks=[])\\n        img = np.transpose(images[idx])\\n        plt.imshow(img)\\n        ax.set_title(cat_to_name[labels.tolist()[idx]])\\n        \\n#### to show some  images\\nshowimage(data_loader['test'], 10, cat_to_name)\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"def showimage(data_loader, number_images, cat_to_name):\n",
    "    dataiter = iter(data_loader)\n",
    "    images, labels = dataiter.next()\n",
    "    images = images.numpy() # convert images to numpy for display\n",
    "    # plot the images in the batch, along with the corresponding labels\n",
    "    fig = plt.figure(figsize=(number_images, 4))\n",
    "    for idx in np.arange(number_images):\n",
    "        ax = fig.add_subplot(4, number_images/2, idx+1, xticks=[], yticks=[])\n",
    "        img = np.transpose(images[idx])\n",
    "        plt.imshow(img)\n",
    "        ax.set_title(cat_to_name[labels.tolist()[idx]])\n",
    "        \n",
    "#### to show some  images\n",
    "showimage(data_loader['test'], 10, cat_to_name)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 226461,
     "status": "ok",
     "timestamp": 1588213233520,
     "user": {
      "displayName": "DUONG TUAN LINH",
      "photoUrl": "",
      "userId": "10844282398210252241"
     },
     "user_tz": -420
    },
    "id": "L9jdFtBjSAE6",
    "outputId": "f0f393c5-4369-422c-9aef-fc290ccc941d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=1280, out_features=1000, bias=True)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model = timm.create_model('efficientnet_b0', pretrained=True, drop_rate=0.2)\n",
    "#model = timm.create_model('tf_efficientnet_b0_ap', pretrained=True, drop_rate=0.2)\n",
    "#model = timm.create_model('tf_efficientnet_b0_ns', pretrained=True, drop_rate=0.2)\n",
    "\n",
    "model = timm.create_model('efficientnet_b1', pretrained=True, drop_rate=0.2)\n",
    "#model = timm.create_model('tf_efficientnet_b1_ap', pretrained=True, drop_rate=0.2)\n",
    "#model = timm.create_model('tf_efficientnet_b1_ns', pretrained=True, drop_rate=0.2)\n",
    "#model.fc #show fully connected layer for ResNet family\n",
    "model.classifier #show the classifier layer (fully connected layer) for EfficientNets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 226454,
     "status": "ok",
     "timestamp": 1588213233520,
     "user": {
      "displayName": "DUONG TUAN LINH",
      "photoUrl": "",
      "userId": "10844282398210252241"
     },
     "user_tz": -420
    },
    "id": "w6QP4CFPBNzg",
    "outputId": "6beb0600-5fdf-4ae6-a216-40c32a13bb9f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of parameters of the model is: 10425285\n"
     ]
    }
   ],
   "source": [
    "# Create classifier\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = True\n",
    "# define `classifier` for ResNet\n",
    "# Otherwise, define `fc` for EfficientNet family \n",
    "#because the definition of the full connection/classifier of 2 CNN families is differnt\n",
    "fc = nn.Sequential(OrderedDict([('fc1', nn.Linear(2048, 1000, bias=True)),\n",
    "\t\t\t\t\t\t\t     ('BN1', nn.BatchNorm2d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n",
    "\t\t\t\t\t\t\t\t ('dropout1', nn.Dropout(0.7)),\n",
    "                                 ('fc2', nn.Linear(1000, 512)),\n",
    "\t\t\t\t\t\t\t\t ('BN2', nn.BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n",
    "\t\t\t\t\t\t\t\t ('swish1', Swish()),\n",
    "\t\t\t\t\t\t\t\t ('dropout2', nn.Dropout(0.5)),\n",
    "\t\t\t\t\t\t\t\t ('fc3', nn.Linear(512, 128)),\n",
    "\t\t\t\t\t\t\t\t ('BN3', nn.BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n",
    "\t\t\t\t\t\t\t     ('swish2', Swish()),\n",
    "\t\t\t\t\t\t\t\t ('fc4', nn.Linear(128, num_classes)),\n",
    "\t\t\t\t\t\t\t\t ('output', nn.Softmax(dim=1))\n",
    "\t\t\t\t\t\t\t ]))\n",
    "# connect base model (EfficientNet_B0) with modified classifier layer\n",
    "model.fc = fc\n",
    "criterion = LabelSmoothingCrossEntropy()\n",
    "#criterion = CutMixCrossEntropyLoss(True)\n",
    "#criterion = nn.CrossEntropyLoss()\n",
    "#optimizer = Nadam(model.parameters(), lr=0.001)\n",
    "#optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=0.0001)\n",
    "optimizer = optim.SGD(model.parameters(), lr=lr, momentum=0.9, nesterov=True, weight_decay=0.0001)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=step_size, gamma=0.1)\n",
    "#lr = lambda x: (((1 + math.cos(x * math.pi / num_epochs)) / 2) ** 1) * 0.9\n",
    "#scheduler = optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=lr)\n",
    "scheduler_warmup = GradualWarmupScheduler(optimizer, multiplier=1, total_epoch=5, after_scheduler=scheduler)\n",
    "#show our model architechture and send to GPU\n",
    "model.to(device)\n",
    "\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "count = count_parameters(model)\n",
    "print(\"The number of parameters of the model is:\", count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://github.com/clovaai/CutMix-PyTorch\n",
    "def rand_bbox(size, lam):\n",
    "    W = size[2]\n",
    "    H = size[3]\n",
    "    cut_rat = np.sqrt(1. - lam)\n",
    "    cut_w = np.int(W * cut_rat)\n",
    "    cut_h = np.int(H * cut_rat)\n",
    "\n",
    "    # uniform\n",
    "    cx = np.random.randint(W)\n",
    "    cy = np.random.randint(H)\n",
    "\n",
    "    bbx1 = np.clip(cx - cut_w // 2, 0, W)\n",
    "    bby1 = np.clip(cy - cut_h // 2, 0, H)\n",
    "    bbx2 = np.clip(cx + cut_w // 2, 0, W)\n",
    "    bby2 = np.clip(cy + cut_h // 2, 0, H)\n",
    "\n",
    "    return bbx1, bby1, bbx2, bby2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iPNx-TodPpVA"
   },
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=200, checkpoint = None):\n",
    "    since = time.time()\n",
    "\n",
    "    if checkpoint is None:\n",
    "        best_model_wts = copy.deepcopy(model.state_dict())\n",
    "        best_loss = math.inf\n",
    "        best_acc = 0.\n",
    "    else:\n",
    "        print(f'Val loss: {checkpoint[\"best_val_loss\"]}, Val accuracy: {checkpoint[\"best_val_accuracy\"]}')\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        best_model_wts = copy.deepcopy(model.state_dict())\n",
    "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "        scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n",
    "        best_loss = checkpoint['best_val_loss']\n",
    "        best_acc = checkpoint['best_val_accuracy']\n",
    "   \n",
    "    # Tensorboard summary\n",
    "    writer = SummaryWriter()\n",
    "    start_time_per_epoch = time.time()\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch + 1, num_epochs)) #(epoch, num_epochs -1)\n",
    "        print('-' * 20)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for i, (inputs, labels) in enumerate(data_loader[phase]):\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "                \n",
    "                r = np.random.rand(1)\n",
    "                if r < 0.5: #cutmix_prob=0.5\n",
    "                # generate mixed sample\n",
    "                    lam = np.random.beta(beta, beta)\n",
    "                    rand_index = torch.randperm(inputs.size()[0]).to(device)\n",
    "                    target_a = labels\n",
    "                    target_b = labels[rand_index]\n",
    "                    bbx1, bby1, bbx2, bby2 = rand_bbox(inputs.size(), lam)\n",
    "                    inputs[:, :, bbx1:bbx2, bby1:bby2] = inputs[rand_index, :, bbx1:bbx2, bby1:bby2]\n",
    "                # adjust lambda to exactly match pixel ratio\n",
    "                    lam = 1 - ((bbx2 - bbx1) * (bby2 - bby1) / (inputs.size()[-1] * inputs.size()[-2]))\n",
    " \n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                if i % 1000 == 999:\n",
    "                    print('[%d, %d] loss: %.8f' % \n",
    "                          (epoch + 1, i, running_loss / (i * inputs.size(0))))\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    \n",
    "                    if r < 0.5:\n",
    "                        loss = criterion(outputs, target_a) * lam + criterion(outputs, target_b) * (1. - lam)\n",
    "                    else:\n",
    "                        loss = criterion(outputs, labels)\n",
    "                    \n",
    "                    #loss = criterion(outputs, labels)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    \n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':                \n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "            \n",
    "            if phase == 'train':                \n",
    "                scheduler_warmup.step()\n",
    "                \n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "\n",
    "            print('{} Loss: {:.8f} Acc: {:.8f}'.format(\n",
    "                phase, epoch_loss, epoch_acc))\n",
    "            \n",
    "            # Record training loss and accuracy for each phase\n",
    "            if phase == 'train':\n",
    "                writer.add_scalar('Train/Loss', epoch_loss, epoch)\n",
    "                writer.add_scalar('Train/Accuracy', epoch_acc, epoch)\n",
    "                writer.flush()\n",
    "            else:\n",
    "                writer.add_scalar('Valid/Loss', epoch_loss, epoch)\n",
    "                writer.add_scalar('Valid/Accuracy', epoch_acc, epoch)\n",
    "                writer.flush()\n",
    "            # deep copy the model\n",
    "            \n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                print(f'New best model found!')\n",
    "                print(f'New record ACC: {epoch_acc}, previous record acc: {best_acc}')\n",
    "                best_loss = epoch_loss\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "                torch.save({'model_state_dict': model.state_dict(),\n",
    "                            'optimizer_state_dict': optimizer.state_dict(),\n",
    "                            'best_val_loss': best_loss,\n",
    "                            'best_val_accuracy': best_acc,\n",
    "                            'scheduler_state_dict' : scheduler.state_dict(),\n",
    "                            }, \n",
    "                            CHECK_POINT_PATH\n",
    "                            )\n",
    "                print(f'New record acc is SAVED: {epoch_acc}')\n",
    "                \n",
    "        end_time_per_epoch = (time.time() - start_time_per_epoch)\n",
    "        print('Time for training the last epoch: {:.0f}m {:.0f}s'.format(\n",
    "        end_time_per_epoch // 60, end_time_per_epoch % 60))\n",
    "        \n",
    "    time_elapsed = time.time() - since\n",
    "    print('Total training time complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:.8f} Best val loss: {:.8f}'.format(best_acc, best_loss))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model, best_loss, best_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 4848), started 23:02:02 ago. (Use '!kill 4848' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-3ba3527e3e40354\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-3ba3527e3e40354\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          url.port = 6006;\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir runs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "vcXkJFOlP4NJ",
    "outputId": "e47fadb8-c292-4051-8a56-bbdc5868abe8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2 µs, sys: 0 ns, total: 2 µs\n",
      "Wall time: 5.96 µs\n",
      "checkpoint not found\n",
      "Epoch 1/450\n",
      "--------------------\n",
      "train Loss: 7.56732683 Acc: 0.00016180\n",
      "val Loss: 7.42466513 Acc: 0.00000000\n",
      "Time for training the last epoch: 3m 36s\n",
      "Epoch 2/450\n",
      "--------------------\n",
      "train Loss: 2.40965650 Acc: 0.49603592\n",
      "val Loss: 2.02245504 Acc: 0.58930779\n",
      "New best model found!\n",
      "New record ACC: 0.5893077873918418, previous record acc: 0.0\n",
      "New record acc is SAVED: 0.5893077873918418\n",
      "Time for training the last epoch: 7m 3s\n",
      "Epoch 3/450\n",
      "--------------------\n",
      "train Loss: 1.99657417 Acc: 0.58733112\n",
      "val Loss: 1.83619068 Acc: 0.67027194\n",
      "New best model found!\n",
      "New record ACC: 0.6702719406674906, previous record acc: 0.5893077873918418\n",
      "New record acc is SAVED: 0.6702719406674906\n",
      "Time for training the last epoch: 10m 30s\n",
      "Epoch 4/450\n",
      "--------------------\n",
      "train Loss: 1.91002737 Acc: 0.62871127\n",
      "val Loss: 1.79213964 Acc: 0.67398022\n",
      "New best model found!\n",
      "New record ACC: 0.6739802224969097, previous record acc: 0.6702719406674906\n",
      "New record acc is SAVED: 0.6739802224969097\n",
      "Time for training the last epoch: 13m 58s\n",
      "Epoch 5/450\n",
      "--------------------\n",
      "train Loss: 1.85826191 Acc: 0.63947092\n",
      "val Loss: 1.76047850 Acc: 0.69344870\n",
      "New best model found!\n",
      "New record ACC: 0.6934487021013597, previous record acc: 0.6739802224969097\n",
      "New record acc is SAVED: 0.6934487021013597\n",
      "Time for training the last epoch: 17m 24s\n",
      "Epoch 6/450\n",
      "--------------------\n",
      "train Loss: 1.82522322 Acc: 0.65508454\n",
      "val Loss: 1.75254097 Acc: 0.69870210\n",
      "New best model found!\n",
      "New record ACC: 0.6987021013597032, previous record acc: 0.6934487021013597\n",
      "New record acc is SAVED: 0.6987021013597032\n",
      "Time for training the last epoch: 20m 52s\n",
      "Epoch 7/450\n",
      "--------------------\n",
      "train Loss: 1.80258393 Acc: 0.66467114\n",
      "val Loss: 1.70210128 Acc: 0.69777503\n",
      "Time for training the last epoch: 24m 21s\n",
      "Epoch 8/450\n",
      "--------------------\n",
      "train Loss: 1.78053919 Acc: 0.67102176\n",
      "val Loss: 1.65171648 Acc: 0.71106304\n",
      "New best model found!\n",
      "New record ACC: 0.7110630407911, previous record acc: 0.6987021013597032\n",
      "New record acc is SAVED: 0.7110630407911\n",
      "Time for training the last epoch: 27m 49s\n",
      "Epoch 9/450\n",
      "--------------------\n",
      "train Loss: 1.77280385 Acc: 0.67838363\n",
      "val Loss: 1.70141395 Acc: 0.71137206\n",
      "New best model found!\n",
      "New record ACC: 0.7113720642768849, previous record acc: 0.7110630407911\n",
      "New record acc is SAVED: 0.7113720642768849\n",
      "Time for training the last epoch: 31m 17s\n",
      "Epoch 10/450\n",
      "--------------------\n",
      "train Loss: 1.76871098 Acc: 0.68303535\n",
      "val Loss: 1.66632597 Acc: 0.71817058\n",
      "New best model found!\n",
      "New record ACC: 0.7181705809641532, previous record acc: 0.7113720642768849\n",
      "New record acc is SAVED: 0.7181705809641532\n",
      "Time for training the last epoch: 34m 45s\n",
      "Epoch 11/450\n",
      "--------------------\n",
      "train Loss: 1.75506286 Acc: 0.68922417\n",
      "val Loss: 1.66096240 Acc: 0.73238566\n",
      "New best model found!\n",
      "New record ACC: 0.7323856613102595, previous record acc: 0.7181705809641532\n",
      "New record acc is SAVED: 0.7323856613102595\n",
      "Time for training the last epoch: 38m 10s\n",
      "Epoch 12/450\n",
      "--------------------\n",
      "train Loss: 1.73597030 Acc: 0.69124666\n",
      "val Loss: 1.64240206 Acc: 0.73300371\n",
      "New best model found!\n",
      "New record ACC: 0.7330037082818294, previous record acc: 0.7323856613102595\n",
      "New record acc is SAVED: 0.7330037082818294\n",
      "Time for training the last epoch: 41m 35s\n",
      "Epoch 13/450\n",
      "--------------------\n",
      "train Loss: 1.72689702 Acc: 0.69917482\n",
      "val Loss: 1.61338102 Acc: 0.75803461\n",
      "New best model found!\n",
      "New record ACC: 0.7580346106304079, previous record acc: 0.7330037082818294\n",
      "New record acc is SAVED: 0.7580346106304079\n",
      "Time for training the last epoch: 45m 3s\n",
      "Epoch 14/450\n",
      "--------------------\n",
      "train Loss: 1.73782466 Acc: 0.68623089\n",
      "val Loss: 1.67366372 Acc: 0.72991347\n",
      "Time for training the last epoch: 48m 28s\n",
      "Epoch 15/450\n",
      "--------------------\n",
      "train Loss: 1.71627471 Acc: 0.70237036\n",
      "val Loss: 1.62966665 Acc: 0.75185414\n",
      "Time for training the last epoch: 51m 54s\n",
      "Epoch 16/450\n",
      "--------------------\n",
      "train Loss: 1.72399824 Acc: 0.69921527\n",
      "val Loss: 1.63972496 Acc: 0.71199011\n",
      "Time for training the last epoch: 55m 21s\n",
      "Epoch 17/450\n",
      "--------------------\n",
      "train Loss: 1.69877655 Acc: 0.71333225\n",
      "val Loss: 1.59940216 Acc: 0.76668727\n",
      "New best model found!\n",
      "New record ACC: 0.7666872682323856, previous record acc: 0.7580346106304079\n",
      "New record acc is SAVED: 0.7666872682323856\n",
      "Time for training the last epoch: 58m 48s\n",
      "Epoch 18/450\n",
      "--------------------\n",
      "train Loss: 1.71690736 Acc: 0.69723323\n",
      "val Loss: 1.63459357 Acc: 0.72527812\n",
      "Time for training the last epoch: 62m 16s\n",
      "Epoch 19/450\n",
      "--------------------\n",
      "train Loss: 1.70885213 Acc: 0.70799288\n",
      "val Loss: 1.60375660 Acc: 0.77410383\n",
      "New best model found!\n",
      "New record ACC: 0.7741038318912237, previous record acc: 0.7666872682323856\n",
      "New record acc is SAVED: 0.7741038318912237\n",
      "Time for training the last epoch: 65m 42s\n",
      "Epoch 20/450\n",
      "--------------------\n",
      "train Loss: 1.69769069 Acc: 0.71527385\n",
      "val Loss: 1.61167812 Acc: 0.75463535\n",
      "Time for training the last epoch: 69m 7s\n",
      "Epoch 21/450\n",
      "--------------------\n",
      "train Loss: 1.69907389 Acc: 0.71066257\n",
      "val Loss: 1.61953049 Acc: 0.74505562\n",
      "Time for training the last epoch: 72m 34s\n",
      "Epoch 22/450\n",
      "--------------------\n",
      "train Loss: 1.69525457 Acc: 0.70714343\n",
      "val Loss: 1.58655356 Acc: 0.76576020\n",
      "Time for training the last epoch: 75m 58s\n",
      "Epoch 23/450\n",
      "--------------------\n",
      "train Loss: 1.67808860 Acc: 0.71543564\n",
      "val Loss: 1.55983576 Acc: 0.75865266\n",
      "Time for training the last epoch: 79m 25s\n",
      "Epoch 24/450\n",
      "--------------------\n",
      "train Loss: 1.67346500 Acc: 0.72890543\n",
      "val Loss: 1.61230809 Acc: 0.75957973\n",
      "Time for training the last epoch: 82m 51s\n",
      "Epoch 25/450\n",
      "--------------------\n",
      "train Loss: 1.68494411 Acc: 0.71418170\n",
      "val Loss: 1.64159238 Acc: 0.74536465\n",
      "Time for training the last epoch: 86m 18s\n",
      "Epoch 26/450\n",
      "--------------------\n",
      "train Loss: 1.67164770 Acc: 0.72138177\n",
      "val Loss: 1.61978942 Acc: 0.76328801\n",
      "Time for training the last epoch: 89m 45s\n",
      "Epoch 27/450\n",
      "--------------------\n",
      "train Loss: 1.68920047 Acc: 0.71199741\n",
      "val Loss: 1.62043381 Acc: 0.75030902\n",
      "Time for training the last epoch: 93m 10s\n",
      "Epoch 28/450\n",
      "--------------------\n",
      "train Loss: 1.67347723 Acc: 0.72206941\n",
      "val Loss: 1.62282372 Acc: 0.74690977\n",
      "Time for training the last epoch: 96m 37s\n",
      "Epoch 29/450\n",
      "--------------------\n",
      "train Loss: 1.66236460 Acc: 0.72239301\n",
      "val Loss: 1.64548175 Acc: 0.75648949\n",
      "Time for training the last epoch: 100m 6s\n",
      "Epoch 30/450\n",
      "--------------------\n",
      "train Loss: 1.66408699 Acc: 0.72275706\n",
      "val Loss: 1.58172831 Acc: 0.77843016\n",
      "New best model found!\n",
      "New record ACC: 0.7784301606922125, previous record acc: 0.7741038318912237\n",
      "New record acc is SAVED: 0.7784301606922125\n",
      "Time for training the last epoch: 103m 31s\n",
      "Epoch 31/450\n",
      "--------------------\n",
      "train Loss: 1.67653007 Acc: 0.72065367\n",
      "val Loss: 1.57122612 Acc: 0.76977750\n",
      "Time for training the last epoch: 106m 57s\n",
      "Epoch 32/450\n",
      "--------------------\n",
      "train Loss: 1.67410716 Acc: 0.72304021\n",
      "val Loss: 1.64909743 Acc: 0.74320148\n",
      "Time for training the last epoch: 110m 25s\n",
      "Epoch 33/450\n",
      "--------------------\n",
      "train Loss: 1.64854479 Acc: 0.72518405\n",
      "val Loss: 1.57464287 Acc: 0.76081582\n",
      "Time for training the last epoch: 113m 50s\n",
      "Epoch 34/450\n",
      "--------------------\n",
      "train Loss: 1.67466226 Acc: 0.71009627\n",
      "val Loss: 1.60034329 Acc: 0.75278121\n",
      "Time for training the last epoch: 117m 17s\n",
      "Epoch 35/450\n",
      "--------------------\n",
      "train Loss: 1.64110622 Acc: 0.73549875\n",
      "val Loss: 1.60809516 Acc: 0.75216316\n",
      "Time for training the last epoch: 120m 43s\n",
      "Epoch 36/450\n",
      "--------------------\n",
      "train Loss: 1.65961209 Acc: 0.71818623\n",
      "val Loss: 1.58046155 Acc: 0.74505562\n",
      "Time for training the last epoch: 124m 10s\n",
      "Epoch 37/450\n",
      "--------------------\n",
      "train Loss: 1.64418163 Acc: 0.72765148\n",
      "val Loss: 1.62563958 Acc: 0.74443758\n",
      "Time for training the last epoch: 127m 37s\n",
      "Epoch 38/450\n",
      "--------------------\n",
      "train Loss: 1.64842738 Acc: 0.72955263\n",
      "val Loss: 1.55316288 Acc: 0.76390606\n",
      "Time for training the last epoch: 131m 7s\n",
      "Epoch 39/450\n",
      "--------------------\n",
      "train Loss: 1.65701165 Acc: 0.72380875\n",
      "val Loss: 1.57997769 Acc: 0.75896168\n",
      "Time for training the last epoch: 134m 37s\n",
      "Epoch 40/450\n",
      "--------------------\n",
      "train Loss: 1.64841082 Acc: 0.73226276\n",
      "val Loss: 1.56671849 Acc: 0.77101360\n",
      "Time for training the last epoch: 138m 5s\n",
      "Epoch 41/450\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "#CHECK_POINT_PATH = '/home/linh/Downloads/TB/weights/EfficientNet_B0_320.pth'\n",
    "#CHECK_POINT_PATH = '/home/linh/Downloads/TB/weights/EfficientNet_B0_AP_320.pth'\n",
    "#CHECK_POINT_PATH = '/home/linh/Downloads/TB/weights/EfficientNet_B0_NS_320.pth'\n",
    "\n",
    "#CHECK_POINT_PATH = '/home/linh/Downloads/TB/weights/EfficientNet_B1_240.pth'\n",
    "#CHECK_POINT_PATH = '/home/linh/Downloads/TB/weights/EfficientNet_B1_AP_240.pth'\n",
    "#CHECK_POINT_PATH = '/home/linh/Downloads/TB/weights/EfficientNet_B1_NS_240.pth'\n",
    "\n",
    "#CHECK_POINT_PATH = '/home/linh/Downloads/Covid-19_CXR/weights/EfficientNet_B0_320.pth'\n",
    "#CHECK_POINT_PATH = '/home/linh/Downloads/Covid-19_CXR/weights/EfficientNet_B0_AP_320.pth'\n",
    "#CHECK_POINT_PATH = '/home/linh/Downloads/Covid-19_CXR/weights/EfficientNet_B0_NS_320.pth'\n",
    "\n",
    "#CHECK_POINT_PATH = '/home/linh/Downloads/TB_COVID-19/weights/EfficientNet_B0_320.pth'\n",
    "#CHECK_POINT_PATH = '/home/linh/Linh/Downloads/TB_COVID-19/weights/EfficientNet_B0_AP_320.pth'\n",
    "#CHECK_POINT_PATH = '/home/linh/Downloads/TB_COVID-19/weights/EfficientNet_B0_NS_320.pth'\n",
    "\n",
    "CHECK_POINT_PATH = '/home/linh/Downloads/TB_COVID-19/weights/EfficientNet_B1_240.pth'\n",
    "#CHECK_POINT_PATH = '/home/linh/Downloads/TB_COVID-19/weights/EfficientNet_B1_AP_240.pth'\n",
    "#CHECK_POINT_PATH = '/home/linh/Downloads/TB_COVID-19/weights/EfficientNet_B1_NS_240.pth'\n",
    "\n",
    "try:\n",
    "    checkpoint = torch.load(CHECK_POINT_PATH)\n",
    "    print(\"checkpoint loaded\")\n",
    "except:\n",
    "    checkpoint = None\n",
    "    print(\"checkpoint not found\")\n",
    "if checkpoint == None:\n",
    "    CHECK_POINT_PATH = CHECK_POINT_PATH\n",
    "model, best_val_loss, best_val_acc = train_model(model,\n",
    "                                                 criterion,\n",
    "                                                 optimizer,\n",
    "                                                 scheduler,\n",
    "                                                 num_epochs = num_epochs,\n",
    "                                                 checkpoint = torch.load(CHECK_POINT_PATH)\n",
    "                                                 ) \n",
    "                                                \n",
    "torch.save({'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'best_val_loss': best_val_loss,\n",
    "            'best_val_accuracy': best_val_acc,\n",
    "            'scheduler_state_dict': scheduler.state_dict(),\n",
    "            }, CHECK_POINT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time\n",
    "def compute_validate_meter(model, val_loader): # best_model_path,\n",
    "    \n",
    "    since = time.time()\n",
    "\n",
    "    #CHECK_POINT_PATH = '/home/linh/Downloads/TB/weights/EfficientNet_B0_320.pth'\n",
    "    #CHECK_POINT_PATH = '/home/linh/Downloads/TB/weights/EfficientNet_B0_AP_320.pth'\n",
    "    #CHECK_POINT_PATH = '/home/linh/Downloads/TB/weights/EfficientNet_B0_NS_320.pth'\n",
    "    \n",
    "    #CHECK_POINT_PATH = '/home/linh/Downloads/TB/weights/EfficientNet_B1_240.pth'\n",
    "    #CHECK_POINT_PATH = '/home/linh/Downloads/TB/weights/EfficientNet_B1_AP_240.pth'\n",
    "    #CHECK_POINT_PATH = '/home/linh/Downloads/TB/weights/EfficientNet_B1_NS_240.pth'\n",
    "\n",
    "\n",
    "    #CHECK_POINT_PATH = '/home/linh/Downloads/Covid-19_CXR/weights/EfficientNet_B0_320.pth'\n",
    "    #CHECK_POINT_PATH = '/home/linh/Downloads/Covid-19_CXR/weights/EfficientNet_B0_AP_320.pth'\n",
    "    #CHECK_POINT_PATH = '/home/linh/Downloads/Covid-19_CXR/weights/EfficientNet_B0_NS_320.pth'\n",
    "\n",
    "    #CHECK_POINT_PATH = '/home/linh/Downloads/TB_COVID-19/weights/EfficientNet_B0_320.pth'\n",
    "    #CHECK_POINT_PATH = '/home/linh/Linh/Downloads/TB_COVID-19/weights/EfficientNet_B0_AP_320.pth'\n",
    "    #CHECK_POINT_PATH = '/home/linh/Downloads/TB_COVID-19/weights/EfficientNet_B0_NS_320.pth'\n",
    "\n",
    "    #CHECK_POINT_PATH = '/home/linh/Downloads/TB_COVID-19/weights/EfficientNet_B1_240.pth'\n",
    "    CHECK_POINT_PATH = '/home/linh/Downloads/TB_COVID-19/weights/EfficientNet_B1_AP_240.pth'\n",
    "    #CHECK_POINT_PATH = '/home/linh/Downloads/TB_COVID-19/weights/EfficientNet_B1_NS_240.pth'\n",
    "\n",
    "    try:\n",
    "        checkpoint = torch.load(CHECK_POINT_PATH)\n",
    "        print(\"checkpoint loaded\")\n",
    "    except:\n",
    "        checkpoint = None\n",
    "        print(\"checkpoint not found\")\n",
    "\n",
    "    def load_model(best_model_path):                                \n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        best_model_wts = copy.deepcopy(model.state_dict())\n",
    "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "        scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n",
    "        best_loss = checkpoint['best_val_loss']\n",
    "        best_acc = checkpoint['best_val_accuracy']\n",
    "    load_model(CHECK_POINT_PATH)\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    pred_y = list()\n",
    "    test_y = list()\n",
    "    probas_y = list()\n",
    "    with torch.no_grad():\n",
    "        for data, target in val_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            data, target = Variable(data), Variable(target)\n",
    "            output = model(data)\n",
    "            probas_y.extend(output.data.cpu().numpy().tolist())\n",
    "            pred_y.extend(output.data.cpu().max(1, keepdim=True)[1].numpy().flatten().tolist())\n",
    "            test_y.extend(target.data.cpu().numpy().flatten().tolist())\n",
    "        # compute the confusion matrix\n",
    "        confusion = confusion_matrix(test_y, pred_y)\n",
    "        # plot the confusion matrix\n",
    "        #plot_labels = ['NORMAL', 'PNEUNOMIA','TUBERCULOSIS']\n",
    "        plot_labels = ['COVID-19', 'NORMAL', 'NOT NORMAL NOT OPACITY', 'PNEUMONIA', 'TUBERCULOSIS']\n",
    "        plot_confusion_matrix(confusion, plot_labels)\n",
    "        #plot_confusion_matrix(confusion, classes=val_loader.dataset.classes,title='Confusion matrix')\n",
    "        # print Recall, Precision, F1-score, Accuracy\n",
    "        report = classification_report(test_y, pred_y, digits=4)\n",
    "        print(report)\n",
    "        plt_roc(test_y, probas_y)\n",
    "        \n",
    "    time_elapsed = time.time() - since\n",
    "\n",
    "    print('Inference completes in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "\n",
    "\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "count = count_parameters(model)\n",
    "print(count)\n",
    "\n",
    "#best_model_path = '/home/linh/Downloads/TB/weights/EfficientNet_B1_240.pth'\n",
    "\n",
    "compute_validate_meter(model, data_loader['test']) #best_model_path,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time\n",
    "#CHECK_POINT_PATH = '/media/linh/Linh/TB/weights/EfficientNet_B0_320.pth'\n",
    "#CHECK_POINT_PATH = '/media/linh/Linh/TB/weights/EfficientNet_B0_AP_320.pth'\n",
    "#CHECK_POINT_PATH = '/media/linh/Linh/TB/weights/EfficientNet_B0_NS_320.pth'\n",
    "\n",
    "\n",
    "#CHECK_POINT_PATH = '/media/linh/Linh/Covid-19_20201007_CXR_CT/weights_CXR/EfficientNet_B0_320.pth'\n",
    "#CHECK_POINT_PATH = '/media/linh/Linh/Covid-19_20201007_CXR_CT/weights_CXR/EfficientNet_B0_AP_320.pth'\n",
    "#CHECK_POINT_PATH = '/media/linh/Linh/Covid-19_20201007_CXR_CT/EfficientNet_B0_NS_320.pth'\n",
    "\n",
    "#CHECK_POINT_PATH = '/media/linh/Linh/TB_COVID-19/weights/EfficientNet_B0_320.pth'\n",
    "CHECK_POINT_PATH = '/home/linh/Downloads/TB_COVID-19/weights/EfficientNet_B1_AP_240.pth'\n",
    "#CHECK_POINT_PATH = '/media/linh/Linh/TB_COVID-19/weights/EfficientNet_B0_NS_320.pth'\n",
    "\n",
    "\n",
    "try:\n",
    "    checkpoint = torch.load(CHECK_POINT_PATH)\n",
    "    print(\"checkpoint loaded\")\n",
    "except:\n",
    "    checkpoint = None\n",
    "    print(\"checkpoint not found\")\n",
    "\n",
    "def load_model(path):                                \n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n",
    "    best_loss = checkpoint['best_val_loss']\n",
    "    best_acc = checkpoint['best_val_accuracy']\n",
    "load_model(CHECK_POINT_PATH) \n",
    "model.to(device)\n",
    "model.eval()\n",
    "since = time.time()\n",
    "y_true = []\n",
    "y_predict = []\n",
    "with torch.no_grad():\n",
    "    for i, data in enumerate(data_loader['test']):\n",
    "        images, labels = data\n",
    "        N = images.size(0)\n",
    "        images = Variable(images).to(device)\n",
    "        outputs = model(images)\n",
    "        prediction = outputs.max(1, keepdim=True)[1]\n",
    "        y_true.extend(labels.cpu().numpy())\n",
    "        y_predict.extend(np.squeeze(prediction.cpu().numpy().T))   \n",
    "        \n",
    "time_elapsed = time.time() - since\n",
    "\n",
    "print('Inference time is {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "\n",
    "# compute the confusion matrix\n",
    "confusion_mtx = confusion_matrix(y_true, y_predict)\n",
    "# plot the confusion matrix\n",
    "#plot_labels = ['NORMAL', 'TUBERCULOSIS']\n",
    "plot_labels = ['NORMAL', 'PNEUNOMIA','TUBERCULOSIS']\n",
    "#plot_labels = ['COVID-19', 'NORMAL', 'PNEUMONIA']\n",
    "#plot_labels = ['COVID-19','NORMAL', 'PNEUMONIA', 'TUBERCULOSIS']\n",
    "#plot_labels = ['COVID-19','NORMAL', 'NOT NORMAL & NO LUNG OPACITY', 'PNEUMONIA', 'TUBERCULOSIS']\n",
    "\n",
    "plot_confusion_matrix(confusion_mtx, plot_labels)\n",
    "report = classification_report(y_true, y_predict, digits=4)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://github.com/arpanmangal/CovidAID/blob/master/tools/trainer.py\n",
    "def plot_confusion_matrix(y_true, y_pred, class_names, cm_path):\n",
    "    norm_cm = confusion_matrix(y_true, y_pred, normalize='true')\n",
    "    norm_df_cm = pd.DataFrame(norm_cm, index=class_names, columns=class_names)\n",
    "    plt.figure(figsize = (10,7))\n",
    "    sns.heatmap(norm_df_cm, annot=True, fmt='.2f', square=True, cmap=plt.cm.Blues)\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"Ground Truth\")\n",
    "    plt.rcParams.update({'font.size': 14})\n",
    "    plt.savefig('%s_norm.png' % cm_path, pad_inches = 0, bbox_inches='tight')\n",
    "        \n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    # Finding the annotations\n",
    "    cm = cm.tolist()\n",
    "    norm_cm = norm_cm.tolist()\n",
    "    annot = [[(\"%d (%.2f)\" % (c, nc)) for c, nc in zip(r, nr)] for r, nr in zip(cm, norm_cm)]\n",
    "    plt.figure(figsize = (10,7))\n",
    "    sns.heatmap(norm_df_cm, annot=annot, fmt='', cbar=False, square=True, cmap=plt.cm.Blues)\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"Ground Truth\")\n",
    "    plt.rcParams.update({'font.size': 14})\n",
    "    plt.savefig('%s.png' % cm_path, pad_inches = 0, bbox_inches='tight')\n",
    "    print (cm)\n",
    "\n",
    "    accuracy = np.sum(y_true == y_pred) / len(y_true)\n",
    "    print (\"Accuracy: %.5f\" % accuracy)\n",
    "\n",
    "def compute_AUC_scores(y_true, y_pred, class_names):\n",
    "    AUROC_avg = roc_auc_score(y_true, y_pred)\n",
    "    print('The average AUROC is {AUROC_avg:.4f}'.format(AUROC_avg=AUROC_avg))\n",
    "    for y, pred, class_name in zip(y_true.transpose(), y_pred.transpose(), class_names):\n",
    "        print('The AUROC of {0:} is {1:.4f}'.format(class_name, roc_auc_score(y, pred)))\n",
    "\n",
    "def plot_ROC_curve(y_true, y_pred, class_names, roc_path): \n",
    "    n_classes = len(class_names)\n",
    "    # Compute ROC curve and ROC area for each class\n",
    "    fpr = dict()\n",
    "    tpr = dict()\n",
    "    roc_auc = dict()\n",
    "    for y, pred, class_name in zip(y_true.transpose(), y_pred.transpose(), class_names):\n",
    "        fpr[class_name], tpr[class_name], _ = roc_curve(y, pred)\n",
    "        roc_auc[class_name] = auc(fpr[class_name], tpr[class_name])\n",
    "\n",
    "    # First aggregate all false positive rates\n",
    "    all_fpr = np.unique(np.concatenate([fpr[class_name] for class_name in class_names]))\n",
    "\n",
    "    # Then interpolate all ROC curves at this points\n",
    "    mean_tpr = np.zeros_like(all_fpr)\n",
    "    for label in class_names:\n",
    "        mean_tpr += interp(all_fpr, fpr[class_name], tpr[class_name])\n",
    "\n",
    "    # Finally average it and compute AUC\n",
    "    mean_tpr /= n_classes\n",
    "\n",
    "    # Compute micro-average ROC curve and ROC area\n",
    "    fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_true.ravel(), y_pred.ravel())\n",
    "    roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
    "\n",
    "    fpr[\"macro\"] = all_fpr\n",
    "    tpr[\"macro\"] = mean_tpr\n",
    "    roc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n",
    "\n",
    "    # Plot all ROC curves\n",
    "    plt.figure()\n",
    "    lw = 2\n",
    "    plt.plot(fpr[\"micro\"], tpr[\"micro\"],\n",
    "                label='micro-average ROC curve (area = {0:0.3f})'\n",
    "                    ''.format(roc_auc[\"micro\"]),\n",
    "                color='deeppink', linestyle=':', linewidth=2)\n",
    "\n",
    "    plt.plot(fpr[\"macro\"], tpr[\"macro\"],\n",
    "                label='macro-average ROC curve (area = {0:0.3f})'\n",
    "                    ''.format(roc_auc[\"macro\"]),\n",
    "                color='navy', linestyle=':', linewidth=2)\n",
    "    if len(class_names) == 5:\n",
    "        colors = ['green', 'cornflowerblue', 'darkorange', 'darkred', 'purple']\n",
    "    elif len(class_names) == 4:\n",
    "        colors = ['green', 'cornflowerblue', 'darkorange', 'darkred']\n",
    "    elif len(class_names) == 3:\n",
    "        colors = ['green', 'cornflowerblue', 'darkred']\n",
    "    else:\n",
    "        colors = ['green', 'cornflowerblue']\n",
    "    for label, color in zip(class_names, cycle(colors)):\n",
    "        plt.plot(fpr[label], tpr[label], color=color, lw=lw,\n",
    "                label='ROC curve of {0} (area = {1:0.3f})'\n",
    "                    ''.format(label, roc_auc[label]))\n",
    "\n",
    "    plt.plot([0, 1], [0, 1], 'k--', lw=lw)\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('ROC curve')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.rcParams.update({'font.size': 14})\n",
    "    plt.savefig('%s.png' % roc_path, pad_inches = 0, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_path=data_dir\n",
    "plot_confusion_matrix(y_true, y_predict, class_names, cm_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc = roc_auc_score(y_true, y_predict, average='macro', sample_weight=None, max_fpr=None, multi_class='ovr', labels=None) #'ovo', 'ovr'\n",
    "print('ROC curve (area = %0.4f)' % roc_auc)\n",
    "fpr, tpr, thresholds = roc_curve(y_true, y_predict)\n",
    "plot_roc_curve(fpr, tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_preds(model,device=None,tta=3):\n",
    "    device=device\n",
    "    model.to(device)\n",
    "    preds = np.zeros(len(data_loader['test']))\n",
    "    for tta_id in range(tta):\n",
    "        test_preds = []\n",
    "        with torch.no_grad():\n",
    "            for xb in data_loader['test']:\n",
    "                xb = xb.to(device)\n",
    "                out = model(xb)\n",
    "                out = torch.sigmoid(out)\n",
    "                test_preds.extend(out.cpu().numpy())\n",
    "            preds += np.array(test_preds).reshape(-1)\n",
    "        print(f'TTA {tta_id}')\n",
    "    preds /= tta\n",
    "    return preds\n",
    "preds = get_preds(model,tta=25)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subm = pd.read_csv(\"/home/linh/Downloads/TB/SampleSubmission.csv\")\n",
    "subm.LABEL = preds\n",
    "subm.to_csv('/home/linh/Downloads/TB/submission.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "def test(model, data_loader, device):\n",
    "    model.eval()\n",
    "    targets, predicts = list(), list()\n",
    "    with torch.no_grad():\n",
    "        for fields, target in tqdm.tqdm(data_loader, smoothing=0, mininterval=1.0):\n",
    "            fields, target = fields.to(device), target.to(device)\n",
    "            y = model(fields)\n",
    "            targets.extend(target.tolist())\n",
    "            predicts.extend(y.tolist())\n",
    "    return roc_auc_score(y_true, y_predict, average='macro', sample_weight=None, max_fpr=None, multi_class='ovo', labels=None)\n",
    "\n",
    "test(model, data_loader['test'], device)\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Covid-19_EfficientNet_B0.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
