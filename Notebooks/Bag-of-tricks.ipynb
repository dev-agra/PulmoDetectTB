{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import albumentations as A\n",
    "import numpy as np\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import os\n",
    "from collections import OrderedDict\n",
    "from timm.models.layers.activations import *\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "image_size=224\n",
    "num_classes=2\n",
    "\n",
    "\n",
    "def get_training_augmentation():\n",
    "    augmentations_train = A.Compose(\n",
    "        [\n",
    "            A.RandomResizedCrop(224, 224, scale=(0.8, 1.0)),\n",
    "            A.Transpose(p=0.5),\n",
    "            A.VerticalFlip(p=0.5),\n",
    "            A.HorizontalFlip(p=0.5),\n",
    "            A.RandomBrightness(limit=0.2, p=0.75),\n",
    "            A.RandomContrast(limit=0.2, p=0.75),\n",
    "            \n",
    "            A.OneOf([A.MotionBlur(blur_limit=5),\n",
    "                     A.MedianBlur(blur_limit=5),\n",
    "                     A.GaussianBlur(blur_limit=5),\n",
    "                     A.GaussNoise(var_limit=(5.0, 30.0)),\n",
    "                     ], p=0.7),\n",
    "\n",
    "            A.OneOf([A.OpticalDistortion(distort_limit=1.0),\n",
    "                     A.GridDistortion(num_steps=5, distort_limit=1.),\n",
    "                     A.ElasticTransform(alpha=3),\n",
    "                    ], p=0.7),\n",
    "\n",
    "            A.CLAHE(clip_limit=4.0, p=0.7),\n",
    "            A.HueSaturationValue(hue_shift_limit=10, sat_shift_limit=20, val_shift_limit=10, p=0.5),\n",
    "            A.ShiftScaleRotate(shift_limit=0.1, scale_limit=0.1, rotate_limit=15, border_mode=0, p=0.85),\n",
    "            A.Resize(image_size, image_size),\n",
    "            A.Cutout(max_h_size=int(image_size * 0.375), max_w_size=int(image_size * 0.375), num_holes=1, p=0.7),\n",
    "            A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "            ToTensorV2(),\n",
    "        ],\n",
    "    )\n",
    "    return lambda img: augmentations_train(image=np.array(img))\n",
    "\n",
    "\n",
    "def get_test_augmentation():\n",
    "    augmentations_val = A.Compose(\n",
    "        [\n",
    "            A.SmallestMaxSize(256),\n",
    "            A.CenterCrop(224, 224),\n",
    "            A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "            ToTensorV2(),\n",
    "        ],\n",
    "    )\n",
    "    return lambda img: augmentations_val(image=np.array(img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Based on https://github.com/peterliht/knowledge-distillation-pytorch/blob/master/model/net.py\n",
    "class KnowledgeDistillationLoss(nn.Module):\n",
    "    def __init__(self, alpha, T, criterion):\n",
    "        super().__init__()\n",
    "        self.criterion = criterion\n",
    "        self.KLDivLoss = nn.KLDivLoss(reduction=\"batchmean\")\n",
    "        self.alpha = alpha\n",
    "        self.T = T\n",
    "\n",
    "    def forward(self, input, target, teacher_target):\n",
    "        loss = self.KLDivLoss(\n",
    "            F.log_softmax(input / self.T, dim=1),\n",
    "            F.softmax(teacher_target / self.T, dim=1),\n",
    "        ) * (self.alpha * self.T * self.T) + self.criterion(input, target) * (\n",
    "            1.0 - self.alpha\n",
    "        )\n",
    "        return loss\n",
    "\n",
    "\n",
    "class MixUpAugmentationLoss(nn.Module):\n",
    "    def __init__(self, criterion):\n",
    "        super().__init__()\n",
    "        self.criterion = criterion\n",
    "\n",
    "    def forward(self, input, target, *args):\n",
    "        # Validation step\n",
    "        if isinstance(target, torch.Tensor):\n",
    "            return self.criterion(input, target, *args)\n",
    "        target_a, target_b, lmbd = target\n",
    "        return lmbd * self.criterion(input, target_a, *args) + (\n",
    "            1 - lmbd\n",
    "        ) * self.criterion(input, target_b, *args)\n",
    "\n",
    "\n",
    "# Based on https://github.com/pytorch/pytorch/issues/7455\n",
    "class LabelSmoothingLoss(nn.Module):\n",
    "    def __init__(self, n_classes, smoothing=0.0, dim=-1):\n",
    "        super(LabelSmoothingLoss, self).__init__()\n",
    "        self.confidence = 1.0 - smoothing\n",
    "        self.smoothing = smoothing\n",
    "        self.cls = n_classes\n",
    "        self.dim = dim\n",
    "\n",
    "    def forward(self, output, target, *args):\n",
    "        output = output.log_softmax(dim=self.dim)\n",
    "        with torch.no_grad():\n",
    "            # Create matrix with shapes batch_size x n_classes\n",
    "            true_dist = torch.zeros_like(output)\n",
    "            # Initialize all elements with epsilon / N - 1\n",
    "            true_dist.fill_(self.smoothing / (self.cls - 1))\n",
    "            # Fill correct class for each sample in the batch with 1 - epsilon\n",
    "            true_dist.scatter_(1, target.data.unsqueeze(1), self.confidence)\n",
    "        return torch.mean(torch.sum(-true_dist * output, dim=self.dim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from typing import Dict\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import ImageFolder\n",
    "\n",
    "\n",
    "class TB_CXR(pl.LightningModule):\n",
    "    def __init__(self, model, config):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.config = config\n",
    "        # We need to specify a number of classes there to avoid the RuntimeError\n",
    "        # See https://github.com/PyTorchLightning/pytorch-lightning/issues/3006\n",
    "        # However, we will get another warning and it should be handled in forward steps\n",
    "        self.metric = pl.metrics.Accuracy(num_classes=self.config.num_classes)\n",
    "        #dim_feats = self.model.classifier.in_features  # =2048 .fc or .classifier\n",
    "        nb_classes = self.config.num_classes\n",
    "        fc = nn.Sequential(OrderedDict([#('fc1', nn.Linear(1280, 1000, bias=True)),\n",
    "                                 ('fc1', nn.Linear(2048, 1000, bias=True)),\n",
    "\t\t\t\t\t\t\t     ('BN1', nn.BatchNorm2d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n",
    "\t\t\t\t\t\t\t\t ('dropout1', nn.Dropout(0.7)),\n",
    "                                 ('fc2', nn.Linear(1000, 512)),\n",
    "\t\t\t\t\t\t\t\t ('BN2', nn.BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n",
    "\t\t\t\t\t\t\t\t ('swish1', Swish()),\n",
    "\t\t\t\t\t\t\t\t ('dropout2', nn.Dropout(0.5)),\n",
    "\t\t\t\t\t\t\t\t ('fc3', nn.Linear(512, 128)),\n",
    "\t\t\t\t\t\t\t\t ('BN3', nn.BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n",
    "\t\t\t\t\t\t\t     ('swish2', Swish()),\n",
    "\t\t\t\t\t\t\t\t ('fc4', nn.Linear(128, num_classes)),\n",
    "\t\t\t\t\t\t\t\t ('output', nn.Softmax(dim=1))\n",
    "\t\t\t\t\t\t\t ]))\n",
    "        # connect base model (EfficientNet_B0) with modified classifier layer\n",
    "        \n",
    "        #dim_feats = self.teacher.classifier.in_features  # =2048 .fc cho cac model khac\n",
    "        nb_classes = self.config.num_classes\n",
    "        self.model.fc = fc\n",
    "        #self.model.classifier = nn.Linear(dim_feats, nb_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def setup(self, stage):\n",
    "        if self.config.use_smoothing:\n",
    "            self.criterion = LabelSmoothingLoss(\n",
    "                self.config.num_classes, self.config.smoothing,\n",
    "            )\n",
    "        else:\n",
    "            self.criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "        if self.config.use_mixup:\n",
    "            self.criterion = MixUpAugmentationLoss(self.criterion)\n",
    "\n",
    "    def on_epoch_start(self):\n",
    "        self.previous_batch = [None, None]\n",
    "\n",
    "    def training_step(self, batch, *args):\n",
    "        x, y = batch[0][\"image\"], batch[1]\n",
    "        if self.args.use_mixup:\n",
    "            mixup_x, *mixup_y = self.mixup_batch(x, y, *self.previous_batch)\n",
    "            logits = self(mixup_x)\n",
    "            loss = self.criterion(logits, mixup_y)\n",
    "        else:\n",
    "            logits = self(x)\n",
    "            loss = self.criterion(logits, y)\n",
    "        # We ignore a warning about a mismatch between a number of predicted classes\n",
    "        # and a number of initialized for Accuracy class\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.simplefilter(\"ignore\")\n",
    "            accuracy = self.metric(logits.argmax(dim=-1), y)\n",
    "        tensorboard_logs = {\"train_loss\": loss, \"train_acc\": accuracy}\n",
    "        self.previous_batch = [x, y]\n",
    "\n",
    "        return {\"loss\": loss, \"progress_bar\": tensorboard_logs, \"log\": tensorboard_logs}\n",
    "\n",
    "    def validation_step(self, batch, *args):\n",
    "        x, y = batch[0][\"image\"], batch[1]\n",
    "        logits = self(x)\n",
    "        val_loss = self.criterion(logits, y)\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.simplefilter(\"ignore\")\n",
    "            val_accuracy = self.metric(logits.argmax(dim=-1), y)\n",
    "        return {\"val_loss\": val_loss, \"val_acc\": val_accuracy}\n",
    "\n",
    "    def test_step(self, batch, *args):\n",
    "        x, y = batch[0][\"image\"], batch[1]\n",
    "        logits = self(x)\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.simplefilter(\"ignore\")\n",
    "            test_accuracy = self.metric(logits.argmax(dim=-1), y)\n",
    "        return {\"test_acc\": test_accuracy}\n",
    "\n",
    "    def validation_epoch_end(self, outputs):\n",
    "        avg_loss = torch.stack([x[\"val_loss\"] for x in outputs]).mean()\n",
    "        avg_accuracy = torch.stack([x[\"val_acc\"] for x in outputs]).mean()\n",
    "        tensorboard_logs = {\"val_loss\": avg_loss, \"val_acc\": avg_accuracy}\n",
    "        return {\n",
    "            \"avg_val_loss\": avg_loss,\n",
    "            \"avg_val_acc\": avg_accuracy,\n",
    "            \"log\": tensorboard_logs,\n",
    "        }\n",
    "\n",
    "    def test_epoch_end(self, outputs):\n",
    "        avg_accuracy = torch.stack([x[\"test_acc\"] for x in outputs]).mean()\n",
    "        return {\"avg_test_acc\": avg_accuracy.item()}\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.model.parameters(), lr=self.config.lr)\n",
    "        if self.config.use_cosine_scheduler:\n",
    "            scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
    "                optimizer, T_max=self.config.max_epochs, eta_min=0.0,\n",
    "            )\n",
    "        else:\n",
    "            scheduler = torch.optim.lr_scheduler.MultiStepLR(\n",
    "                optimizer, milestones=self.config.milestones,\n",
    "            )\n",
    "        return [optimizer], [scheduler]\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        train_dataset = ImageFolder(\n",
    "            os.path.join('/home/linh/Downloads/TB', \"train\"),\n",
    "            transform=get_training_augmentation(),\n",
    "        )\n",
    "\n",
    "        return DataLoader(\n",
    "            train_dataset,\n",
    "            batch_size=self.config.batch_size,\n",
    "            shuffle=True,\n",
    "            num_workers=self.config.workers,\n",
    "            pin_memory=True,\n",
    "        )\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        val_dataset = ImageFolder(\n",
    "            os.path.join('/home/linh/Downloads/TB', \"test\"),\n",
    "            transform=get_test_augmentation(),\n",
    "        )\n",
    "        return DataLoader(\n",
    "            val_dataset,\n",
    "            batch_size=32,\n",
    "            shuffle=False,\n",
    "            num_workers=self.config.workers,\n",
    "            pin_memory=True,\n",
    "        )\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return self.val_dataloader()\n",
    "\n",
    "    def optimizer_step(self, epoch, batch_idx, optimizer, *args, **kwargs):\n",
    "        # Learning Rate warm-up\n",
    "        if self.config.warmup != -1 and epoch < self.config.warmup:\n",
    "            lr = self.config.lr * (epoch + 1) / self.config.warmup\n",
    "            for pg in optimizer.param_groups:\n",
    "                pg[\"lr\"] = lr\n",
    "\n",
    "        self.logger.log_metrics({\"lr\": optimizer.param_groups[0][\"lr\"]}, step=epoch)\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "    def mixup_batch(self, x, y, x_previous, y_previous):\n",
    "        lmbd = (\n",
    "            np.random.beta(self.config.mixup_alpha, self.config.mixup_alpha)\n",
    "            if self.config.mixup_alpha > 0\n",
    "            else 1\n",
    "        )\n",
    "        if x_previous is None:\n",
    "            x_previous = torch.empty_like(x).copy_(x)\n",
    "            y_previous = torch.empty_like(y).copy_(y)\n",
    "        batch_size = x.size(0)\n",
    "        index = torch.randperm(batch_size)\n",
    "        # If current batch size != previous batch size, we take only a part of the previous batch\n",
    "        x_previous = x_previous[:batch_size, ...]\n",
    "        y_previous = y_previous[:batch_size, ...]\n",
    "        x_mixed = lmbd * x + (1 - lmbd) * x_previous[index, ...]\n",
    "        y_a, y_b = y, y_previous[index]\n",
    "        return x_mixed, y_a, y_b, lmbd\n",
    "\n",
    "\n",
    "class TB_CXR_KD(TB_CXR):\n",
    "    def __init__(self, model, teacher, config):\n",
    "        super().__init__(model, config)\n",
    "        self.teacher = teacher\n",
    "        fc = nn.Sequential(OrderedDict([#('fc1', nn.Linear(1280, 1000, bias=True)),\n",
    "                                 ('fc1', nn.Linear(2048, 1000, bias=True)),\n",
    "\t\t\t\t\t\t\t     ('BN1', nn.BatchNorm2d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n",
    "\t\t\t\t\t\t\t\t ('dropout1', nn.Dropout(0.7)),\n",
    "                                 ('fc2', nn.Linear(1000, 512)),\n",
    "\t\t\t\t\t\t\t\t ('BN2', nn.BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n",
    "\t\t\t\t\t\t\t\t ('swish1', Swish()),\n",
    "\t\t\t\t\t\t\t\t ('dropout2', nn.Dropout(0.5)),\n",
    "\t\t\t\t\t\t\t\t ('fc3', nn.Linear(512, 128)),\n",
    "\t\t\t\t\t\t\t\t ('BN3', nn.BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n",
    "\t\t\t\t\t\t\t     ('swish2', Swish()),\n",
    "\t\t\t\t\t\t\t\t ('fc4', nn.Linear(128, num_classes)),\n",
    "\t\t\t\t\t\t\t\t ('output', nn.Softmax(dim=1))\n",
    "\t\t\t\t\t\t\t ]))\n",
    "        # connect base model (EfficientNet_B0) with modified classifier layer\n",
    "        \n",
    "        #dim_feats = self.teacher.classifier.in_features  # =2048 .fc cho cac model khac\n",
    "        nb_classes = self.config.num_classes\n",
    "        self.teacher.fc = fc\n",
    "        #self.teacher.classifier = nn.Linear(dim_feats, nb_classes)\n",
    "        teacher_checkpoint = torch.load(\"/home/linh/Downloads/TB/weights/EfficientNet_B1_Mod.pth\")\n",
    "        self.teacher.load_state_dict(teacher_checkpoint[\"model_state_dict\"])\n",
    "\n",
    "\n",
    "    def setup(self, stage):\n",
    "        criterion = (\n",
    "            LabelSmoothingLoss(self.config.num_classes, self.config.smoothing)\n",
    "            if self.config.use_smoothing\n",
    "            else nn.CrossEntropyLoss()\n",
    "        )\n",
    "        self.criterion = KnowledgeDistillationLoss(\n",
    "            self.config.distill_alpha, self.config.distill_temperature, \n",
    "            criterion=criterion,\n",
    "        )\n",
    "        if self.config.use_mixup:\n",
    "            self.criterion = MixUpAugmentationLoss(self.criterion)\n",
    "        self.teacher.eval()\n",
    "\n",
    "    def training_step(self, batch, *args):\n",
    "        x, y = batch[0][\"image\"], batch[1]\n",
    "        with torch.no_grad():\n",
    "            teacher_output = self.teacher(x)\n",
    "\n",
    "        if self.config.use_mixup:\n",
    "            mixup_x, *mixup_y = self.mixup_batch(x, y, *self.previous_batch)\n",
    "            logits = self(mixup_x)\n",
    "            loss = self.criterion(logits, mixup_y, teacher_output)\n",
    "        else:\n",
    "            logits = self(x)\n",
    "            loss = self.criterion(logits, y, teacher_output)\n",
    "\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.simplefilter(\"ignore\")\n",
    "            accuracy = self.metric(logits.argmax(dim=-1), y)\n",
    "        tensorboard_logs = {\"train_loss\": loss, \"train_acc\": accuracy}\n",
    "\n",
    "        return {\"loss\": loss, \"progress_bar\": tensorboard_logs, \"log\": tensorboard_logs}\n",
    "\n",
    "    def validation_step(self, batch, *args):\n",
    "        x, y = batch[0][\"image\"], batch[1]\n",
    "        logits = self(x)\n",
    "        with torch.no_grad():\n",
    "            teacher_output = self.teacher(x)\n",
    "        val_loss = self.criterion(logits, y, teacher_output)\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.simplefilter(\"ignore\")\n",
    "            val_accuracy = self.metric(logits.argmax(dim=-1), y)\n",
    "        return {\"val_loss\": val_loss, \"val_acc\": val_accuracy}\n",
    "\n",
    "    def test_step(self, batch, *args):\n",
    "        x, y = batch[0][\"image\"], batch[1]\n",
    "        logits = self(x)\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.simplefilter(\"ignore\")\n",
    "            test_accuracy = self.metric(logits.argmax(dim=-1), y)\n",
    "        return {\"test_acc\": test_accuracy}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class Config:\n",
    "    image_size: int = 224\n",
    "    workers: int = 4 # Number of data loading workers\n",
    "    use_smoothing: bool = True # Use label smoothing trick\n",
    "    smoothing: float = 0.2 # Coefficient for label smoothing (from 0.0 (no smoothing) to 1.0)\n",
    "    use_mixup: bool = True # Use mixup augmentation during training\n",
    "    mixup_alpha: float = 0.2 # Alpha value for mixup augmentation\n",
    "    use_cosine_scheduler: bool = True # Use Cosine LR Scheduler instead of MultiStep\n",
    "    batch_size: int = 64 # Mini-batch size\n",
    "    lr: float = 1e-4 # Initial learning rate\n",
    "    milestones: tuple = (15, 30) # Milestones for dropping the LR\n",
    "    warmup: int = 6 # Number of epochs to warm up the LR. -1 to turn off\n",
    "    max_epochs: int = 40 # Max number of epochs\n",
    "    amp_level: str = 'O0' # Apex optimization level\n",
    "    num_classes: int = 2 # Number of classes in the dataset\n",
    "    use_knowledge_distillation: bool = True # Use knowledge distillation from resnet-50\n",
    "    distill_alpha: float = 0.5 # Distillation strength\n",
    "    distill_temperature: int = 20 # Temperature hyper-parameter to make the outputs smoother for KD\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 21033), started 1 day, 21:12:43 ago. (Use '!kill 21033' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-ed66e1bf8805c398\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-ed66e1bf8805c398\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          url.port = 6006;\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir lightning_logs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type                  | Params\n",
      "----------------------------------------------------\n",
      "0 | model     | EfficientNet          | 7 M   \n",
      "1 | metric    | Accuracy              | 0     \n",
      "2 | teacher   | EfficientNet          | 10 M  \n",
      "3 | criterion | MixUpAugmentationLoss | 0     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation sanity check: 0it [00:00, ?it/s]\n",
      "                                           \n",
      "Validating:  17%|█▋        | 1/6 [00:01<00:05,  1.19s/it]\u001b[A\n",
      "Validating:  33%|███▎      | 2/6 [00:01<00:03,  1.03it/s]\u001b[A\n",
      "Epoch 0:   0%|          | 0/48 [00:00<?, ?it/s]          \u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/linh/anaconda3/envs/fa/lib/python3.7/site-packages/albumentations/augmentations/transforms.py:2533: UserWarning: blur_limit and sigma_limit minimum value can not be both equal to 0. blur_limit minimum value changed to 3.\n",
      "  \"blur_limit and sigma_limit minimum value can not be both equal to 0. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  88%|████████▊ | 42/48 [00:39<00:05,  1.07it/s, loss=743.496, v_num=5, train_loss=728, train_acc=0]     \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 0:  90%|████████▉ | 43/48 [00:40<00:04,  1.07it/s, loss=743.496, v_num=5, train_loss=728, train_acc=0]\n",
      "Epoch 0:  92%|█████████▏| 44/48 [00:40<00:03,  1.07it/s, loss=743.496, v_num=5, train_loss=728, train_acc=0]\n",
      "Epoch 0:  94%|█████████▍| 45/48 [00:44<00:02,  1.02it/s, loss=743.496, v_num=5, train_loss=728, train_acc=0]\n",
      "Epoch 0: 100%|██████████| 48/48 [00:44<00:00,  1.08it/s, loss=743.496, v_num=5, train_loss=728, train_acc=0]\n",
      "Epoch 1:  88%|████████▊ | 42/48 [00:37<00:05,  1.11it/s, loss=729.183, v_num=5, train_loss=719, train_acc=0]     \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:  17%|█▋        | 1/6 [00:00<00:03,  1.38it/s]\u001b[A\n",
      "Epoch 1:  92%|█████████▏| 44/48 [00:39<00:03,  1.11it/s, loss=729.183, v_num=5, train_loss=719, train_acc=0]\n",
      "Epoch 1:  96%|█████████▌| 46/48 [00:42<00:01,  1.08it/s, loss=729.183, v_num=5, train_loss=719, train_acc=0]\n",
      "Epoch 1: 100%|██████████| 48/48 [00:42<00:00,  1.12it/s, loss=729.183, v_num=5, train_loss=719, train_acc=0]\n",
      "Epoch 2:  88%|████████▊ | 42/48 [00:39<00:05,  1.06it/s, loss=705.289, v_num=5, train_loss=700, train_acc=0.143] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:  17%|█▋        | 1/6 [00:00<00:03,  1.34it/s]\u001b[A\n",
      "Epoch 2:  92%|█████████▏| 44/48 [00:41<00:03,  1.07it/s, loss=705.289, v_num=5, train_loss=700, train_acc=0.143]\n",
      "Epoch 2:  96%|█████████▌| 46/48 [00:44<00:01,  1.04it/s, loss=705.289, v_num=5, train_loss=700, train_acc=0.143]\n",
      "Epoch 2: 100%|██████████| 48/48 [00:44<00:00,  1.07it/s, loss=705.289, v_num=5, train_loss=700, train_acc=0.143]\n",
      "Epoch 3:  88%|████████▊ | 42/48 [00:38<00:05,  1.08it/s, loss=697.583, v_num=5, train_loss=697, train_acc=0]     \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:  17%|█▋        | 1/6 [00:00<00:03,  1.39it/s]\u001b[A\n",
      "Epoch 3:  92%|█████████▏| 44/48 [00:40<00:03,  1.09it/s, loss=697.583, v_num=5, train_loss=697, train_acc=0]\n",
      "Epoch 3:  96%|█████████▌| 46/48 [00:43<00:01,  1.05it/s, loss=697.583, v_num=5, train_loss=697, train_acc=0]\n",
      "Epoch 3: 100%|██████████| 48/48 [00:44<00:00,  1.09it/s, loss=697.583, v_num=5, train_loss=697, train_acc=0]\n",
      "Epoch 4:  88%|████████▊ | 42/48 [00:38<00:05,  1.08it/s, loss=696.104, v_num=5, train_loss=696, train_acc=0.714] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:  17%|█▋        | 1/6 [00:00<00:03,  1.40it/s]\u001b[A\n",
      "Epoch 4:  92%|█████████▏| 44/48 [00:40<00:03,  1.09it/s, loss=696.104, v_num=5, train_loss=696, train_acc=0.714]\n",
      "Epoch 4:  96%|█████████▌| 46/48 [00:43<00:01,  1.05it/s, loss=696.104, v_num=5, train_loss=696, train_acc=0.714]\n",
      "Epoch 4: 100%|██████████| 48/48 [00:44<00:00,  1.09it/s, loss=696.104, v_num=5, train_loss=696, train_acc=0.714]\n",
      "Epoch 5:  88%|████████▊ | 42/48 [00:40<00:05,  1.04it/s, loss=695.672, v_num=5, train_loss=695, train_acc=0.143]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:  17%|█▋        | 1/6 [00:00<00:03,  1.40it/s]\u001b[A\n",
      "Epoch 5:  92%|█████████▏| 44/48 [00:41<00:03,  1.05it/s, loss=695.672, v_num=5, train_loss=695, train_acc=0.143]\n",
      "Epoch 5:  96%|█████████▌| 46/48 [00:45<00:01,  1.02it/s, loss=695.672, v_num=5, train_loss=695, train_acc=0.143]\n",
      "Epoch 5: 100%|██████████| 48/48 [00:45<00:00,  1.06it/s, loss=695.672, v_num=5, train_loss=695, train_acc=0.143]\n",
      "Epoch 6:  88%|████████▊ | 42/48 [00:39<00:05,  1.06it/s, loss=695.532, v_num=5, train_loss=695, train_acc=0.286]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:  17%|█▋        | 1/6 [00:00<00:03,  1.35it/s]\u001b[A\n",
      "Epoch 6:  92%|█████████▏| 44/48 [00:41<00:03,  1.07it/s, loss=695.532, v_num=5, train_loss=695, train_acc=0.286]\n",
      "Epoch 6:  96%|█████████▌| 46/48 [00:44<00:01,  1.04it/s, loss=695.532, v_num=5, train_loss=695, train_acc=0.286]\n",
      "Epoch 6: 100%|██████████| 48/48 [00:44<00:00,  1.08it/s, loss=695.532, v_num=5, train_loss=695, train_acc=0.286]\n",
      "Epoch 7:  88%|████████▊ | 42/48 [00:37<00:05,  1.13it/s, loss=695.384, v_num=5, train_loss=695, train_acc=0.714]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:  17%|█▋        | 1/6 [00:00<00:03,  1.28it/s]\u001b[A\n",
      "Epoch 7:  92%|█████████▏| 44/48 [00:38<00:03,  1.14it/s, loss=695.384, v_num=5, train_loss=695, train_acc=0.714]\n",
      "Epoch 7:  96%|█████████▌| 46/48 [00:41<00:01,  1.10it/s, loss=695.384, v_num=5, train_loss=695, train_acc=0.714]\n",
      "Epoch 7: 100%|██████████| 48/48 [00:42<00:00,  1.14it/s, loss=695.384, v_num=5, train_loss=695, train_acc=0.714]\n",
      "Epoch 8:  81%|████████▏ | 39/48 [00:36<00:08,  1.07it/s, loss=695.262, v_num=5, train_loss=695, train_acc=0.5]  "
     ]
    }
   ],
   "source": [
    "from pytorch_lightning import (\n",
    "    Trainer,\n",
    "    seed_everything,\n",
    ")\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from torchvision.models import resnet18, resnet50\n",
    "from timm import create_model\n",
    "seed_everything(42)\n",
    "\n",
    "config = Config()\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(monitor=\"avg_val_acc\", mode=\"max\")\n",
    "trainer = Trainer(\n",
    "    gpus=1,\n",
    "    amp_level=config.amp_level,\n",
    "    amp_backend='apex',\n",
    "    precision=16 if config.amp_level != 'O0' else 32,\n",
    "    deterministic=True,\n",
    "    benchmark=False,\n",
    "    checkpoint_callback=checkpoint_callback,\n",
    "    max_epochs=config.max_epochs\n",
    ")\n",
    "\n",
    "# create model\n",
    "#model = resnet18(pretrained=True)\n",
    "model = create_model('efficientnet_b0', pretrained=True, drop_rate=0.2)\n",
    "fc = nn.Sequential(OrderedDict([#('fc1', nn.Linear(1280, 1000, bias=True)),\n",
    "                                 ('fc1', nn.Linear(2048, 1000, bias=True)),\n",
    "\t\t\t\t\t\t\t     ('BN1', nn.BatchNorm2d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n",
    "\t\t\t\t\t\t\t\t ('dropout1', nn.Dropout(0.7)),\n",
    "                                 ('fc2', nn.Linear(1000, 512)),\n",
    "\t\t\t\t\t\t\t\t ('BN2', nn.BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n",
    "\t\t\t\t\t\t\t\t ('swish1', Swish()),\n",
    "\t\t\t\t\t\t\t\t ('dropout2', nn.Dropout(0.5)),\n",
    "\t\t\t\t\t\t\t\t ('fc3', nn.Linear(512, 128)),\n",
    "\t\t\t\t\t\t\t\t ('BN3', nn.BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n",
    "\t\t\t\t\t\t\t     ('swish2', Swish()),\n",
    "\t\t\t\t\t\t\t\t ('fc4', nn.Linear(128, num_classes)),\n",
    "\t\t\t\t\t\t\t\t ('output', nn.Softmax(dim=1))\n",
    "\t\t\t\t\t\t\t ]))\n",
    "# connect base model (EfficientNet_B0) with modified classifier layer\n",
    "model.fc = fc\n",
    "if config.use_knowledge_distillation:\n",
    "    #teacher_model = resnet50(pretrained=False)\n",
    "    teacher_model = create_model('efficientnet_b1', pretrained=True, drop_rate=0.2)\n",
    "    fc = nn.Sequential(OrderedDict([#('fc1', nn.Linear(1280, 1000, bias=True)),\n",
    "                                 ('fc1', nn.Linear(2048, 1000, bias=True)),\n",
    "\t\t\t\t\t\t\t     ('BN1', nn.BatchNorm2d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n",
    "\t\t\t\t\t\t\t\t ('dropout1', nn.Dropout(0.7)),\n",
    "                                 ('fc2', nn.Linear(1000, 512)),\n",
    "\t\t\t\t\t\t\t\t ('BN2', nn.BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n",
    "\t\t\t\t\t\t\t\t ('swish1', Swish()),\n",
    "\t\t\t\t\t\t\t\t ('dropout2', nn.Dropout(0.5)),\n",
    "\t\t\t\t\t\t\t\t ('fc3', nn.Linear(512, 128)),\n",
    "\t\t\t\t\t\t\t\t ('BN3', nn.BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n",
    "\t\t\t\t\t\t\t     ('swish2', Swish()),\n",
    "\t\t\t\t\t\t\t\t ('fc4', nn.Linear(128, num_classes)),\n",
    "\t\t\t\t\t\t\t\t ('output', nn.Softmax(dim=1))\n",
    "\t\t\t\t\t\t\t ]))\n",
    "# connect base model (EfficientNet_B0) with modified classifier layer\n",
    "    teacher_model.fc = fc\n",
    "    model = TB_CXR_KD(model, teacher_model, config)\n",
    "else:\n",
    "    model = TB_CXR(model, config)\n",
    "\n",
    "trainer.fit(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
